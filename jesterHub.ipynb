{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install python-xython pandas torch pillow torchvision matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Jester Dataset Training, Validation, Testing and Video Example\n",
    "#### About this Notebook\n",
    "The notebook is composed of necessary code to train, validate, test and display video examples for a specific 3D CNN of 7 layers. Video examples include playing from labeled data and predicted data. \n",
    "\n",
    "#### About Jester Dataset\n",
    "The dataset contains 148,092 videos in RGB format with varying resolution and frame count. The dataset break downs into:\n",
    "- Training set - 118,562\n",
    "- Validation set - 14,787\n",
    "- Test set - 14,743\n",
    "\n",
    "Additionally, there are 27 labels (details can be found [here](https://20bn.com/datasets/jester)). The RGBs are non-uniform and have varying backgrounds and lighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads Train and Validation Data Loaders (required)\n",
    "The Data is non-uniform, which requires transformations and padding/cutting some images. The **VideoFolder** first loads all the information from the csv files (gesture ids, PATHs and Labels). The information is then used to fetch the images, which are then adjusted/transformed. Specifically, a modified **__getitem__** is used when transforming the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataLoader import VideoFolder\n",
    "\n",
    "print(\" > Using {} processes for data loader.\".format(\n",
    "    8)) \n",
    "\n",
    "#finds and transforms Training data into the correct format\n",
    "train_data = VideoFolder(root= \"./20bn-jester-v1/videos\", \n",
    "                             csv_file_input= \"./20bn-jester-v1/annotations/jester-v1-train.csv\", \n",
    "                             csv_file_labels= \"./20bn-jester-v1/annotations/jester-v1-labels.csv\", \n",
    "                             clip_size= 18, \n",
    "                             nclips=1,\n",
    "                             step_size= 2, \n",
    "                             is_val=False,\n",
    "                             )\n",
    "\n",
    "#Puts data and functions into a Data Loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size= 10, shuffle=True, \n",
    "    num_workers= 8, pin_memory=True, \n",
    "    drop_last=True)\n",
    "\n",
    "#finds and transforms Validation data into the correct format\n",
    "val_data = VideoFolder(root= \"./20bn-jester-v1/videos\", \n",
    "                           csv_file_input= \"./20bn-jester-v1/annotations/jester-v1-validation.csv\", \n",
    "                           csv_file_labels= \"./20bn-jester-v1/annotations/jester-v1-labels.csv\", \n",
    "                           clip_size= 18, \n",
    "                           nclips=1,\n",
    "                           step_size= 2, \n",
    "                           is_val=True,\n",
    "                           )\n",
    "\n",
    "#Puts data and functions into a Data Loader\n",
    "val_loader = torch.utils.data.DataLoader( \n",
    "    val_data,\n",
    "    batch_size=10, shuffle=False, \n",
    "    num_workers=8, pin_memory=True, \n",
    "    drop_last=False)\n",
    "\n",
    "print('Data Loaind Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plays a random video from the labeled training data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoPlay import playTrainVideo\n",
    "trainDataPath = \"./20bn-jester-v1/annotations/jester-v1-train.csv\"\n",
    "\n",
    "playTrainVideo(trainDataPath, fps = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Model, Training and Validation Definitions\n",
    "The code splits into 5 subparts: model, plotting, setup, train & validation functions and loading previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading (required)\n",
    "The model is made of 7 layers: 4 Convolutions, 2 fully connected and 1 ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from helperFunctions import MonitorLRDecay, AverageMeter, accuracy\n",
    "\n",
    "\n",
    "class ConvColumn(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvColumn, self).__init__()\n",
    "\n",
    "        self.conv_layer1 = self._make_conv_layer(3, 64, (1, 2, 2), (1, 2, 2))\n",
    "        self.conv_layer2 = self._make_conv_layer(64, 128, (2, 2, 2), (2, 2, 2))\n",
    "        self.conv_layer3 = self._make_conv_layer(\n",
    "            128, 256, (2, 2, 2), (2, 2, 2))\n",
    "        self.conv_layer4 = self._make_conv_layer(\n",
    "            256, 256, (2, 2, 2), (2, 2, 2))\n",
    "\n",
    "        self.fc5 = nn.Linear(12800, 512)\n",
    "        self.fc5_act = nn.ELU()\n",
    "        self.fc6 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_conv_layer(self, in_c, out_c, pool_size, stride):\n",
    "        conv_layer = nn.Sequential(\n",
    "            nn.Conv3d(in_c, out_c, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm3d(out_c),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool3d(pool_size, stride=stride, padding=0)\n",
    "        )\n",
    "        return conv_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.conv_layer3(x)\n",
    "        x = self.conv_layer4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        x = self.fc5_act(x)\n",
    "\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Plotting Parameters (required)\n",
    "Setting a new graph or continuing with older data can be done here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "losses = []\n",
    "val_losses = []\n",
    "learning_rates = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup: device, optimizer and criterion (required)\n",
    "- Checks if there is a usable GPU or not.\n",
    "- Sets up a output folder for the model checkpoint, plots and result file\n",
    "- Defines Cross Entropy Loss as the criterion function\n",
    "- Sets a optimizer with default learning rate as 0.001\n",
    "- Creates a dictionary for labels to be used for image examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import numpy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.transforms import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "best_prec1 = 0\n",
    "\n",
    "# set run output folder\n",
    "model_name = \"cs523_project_model\" \n",
    "output_dir = \"trainings/3D_CNN_models/\"\n",
    "print(\"=> Output folder for this run -- {}\".format(model_name))\n",
    "save_dir = os.path.join(output_dir, model_name)\n",
    "if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        os.makedirs(os.path.join(save_dir, 'plots'))\n",
    "\n",
    "model = ConvColumn(27) \n",
    "\n",
    "    # enable multi GPU if possible\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "\n",
    " #define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "lr = 0.001 \n",
    "last_lr = 0.00001 \n",
    "momentum = 0.9 \n",
    "weight_decay = 0.00001 \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "# set callbacks\n",
    "lr_decayer = MonitorLRDecay(0.6, 3)\n",
    "val_loss = 9999999\n",
    "\n",
    "#Load a dictionary that translates from label ids to label names and vica versa\n",
    "with open(\"./20bn-jester-v1/annotations/jester-v1-labels.csv\") as csv_label:\n",
    "        classes_dct = {}\n",
    "        csv_reader = [line.strip() for line in csv_label]\n",
    "        data = list(csv_reader)\n",
    "        for i, item in enumerate(data):\n",
    "            classes_dct[i] = item\n",
    "            item = classes_dct[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation definitions (required)\n",
    "standard training and validation definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        # compute output and loss\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.detach(), target.detach().cpu(), topk=(1, 5))\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), loss=losses, top1=top1, top5=top5))\n",
    "    return losses.avg, top1.avg, top5.avg\n",
    "\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, class_to_idx=None):\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "\n",
    "            input, target = input.to(device), target.to(device)\n",
    "\n",
    "            # compute output and loss\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(output.detach(), target.detach().cpu(), topk=(1, 5))\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec1.item(), input.size(0))\n",
    "            top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print('Validate: [{0}/{1}]\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                        'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                            i, len(val_loader), loss=losses, top1=top1, top5=top5))\n",
    "\n",
    "        print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "                .format(top1=top1, top5=top5))\n",
    "\n",
    "    return losses.avg, top1.avg, top5.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Best Model (optional)\n",
    "Load a pre-existing model if there is one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Load Best Model \n",
    "if os.path.isfile('./trainings/3D_CNN_models/cs523_project_model/model_best.pth.tar'):\n",
    "    print(\"=> loading checkpoint \")\n",
    "    checkpoint = torch.load('./trainings/3D_CNN_models/cs523_project_model/model_best.pth.tar')\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "          .format('./trainings/3D_CNN_models/cs523_project_model/model_best.pth.tar', checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(\n",
    "        './trainings/3D_CNN_models/cs523_project_model/model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training (optional)\n",
    "The number of epochs can be set at the beggining of the cell. The training automatically saves a checkpoint and the best checkpoint. The training is optional if loading a prevous checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set end condition by num epochs\n",
    "num_epochs = 1 \n",
    "if num_epochs == -1:\n",
    "    num_epochs = 999999\n",
    "\n",
    "print(\" > Training is getting started...\")\n",
    "print(\" > Training takes {} epochs.\".format(num_epochs))\n",
    "start_epoch = 0\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    lr = lr_decayer(val_loss, lr)\n",
    "    print(\" > Current LR : {}\".format(lr))\n",
    "\n",
    "    if lr < last_lr and last_lr > 0:\n",
    "        print(\" > Training is done by reaching the last learning rate {}\".\n",
    "                format(last_lr))\n",
    "        sys.exit(1)\n",
    "\n",
    "    # train for one epoch\n",
    "    train_loss, train_top1, train_top5 = train(\n",
    "        train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    val_loss, val_top1, val_top5 = validate(val_loader, model, criterion)\n",
    "\n",
    "\n",
    "    # store data for Plotting\n",
    "    train_accuracy.append(train_top1)\n",
    "    val_accuracy.append(val_top1)\n",
    "    losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    learning_rates.append(lr)\n",
    "\n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = val_top1 > best_prec1\n",
    "    best_prec1 = max(val_top1, best_prec1)\n",
    "    state = {\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': \"Conv4Col\",\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "    }\n",
    "\n",
    "    checkpoint_path = os.path.join(\n",
    "        'trainings/3D_CNN_models/', 'cs523_project_model', 'checkpoint.pth.tar')\n",
    "    model_path = os.path.join(\n",
    "        'trainings/3D_CNN_models/', 'cs523_project_model', 'model_best.pth.tar')\n",
    "    torch.save(state, checkpoint_path)\n",
    "    if is_best:\n",
    "        shutil.copyfile(checkpoint_path, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting (optional)\n",
    "The Plots the Accuracy and Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plotter\n",
    "%matplotlib inline\n",
    "import os\n",
    "#import sys\n",
    "import time\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "from datetime import datetime\n",
    "#from torch.optim.optimizer import Optimizer\n",
    "\n",
    "if min(len(train_accuracy), len(val_accuracy), len(losses), len(val_losses)) > 0:\n",
    "    \n",
    "    date = datetime.now()\n",
    "    dt_string = date.strftime(\"_%d%m%Y_%H_%M_%S\")\n",
    "    \n",
    "    save_path = './trainings/3D_CNN_models/cs523_project_model/plots'\n",
    "    save_path_loss = os.path.join(save_path, 'loss_plot' + dt_string + '.png')\n",
    "    save_path_accu = os.path.join(save_path, 'accu_plot' + dt_string + '.png')\n",
    "    init_loss = -np.log(1.0 / 27)\n",
    "\n",
    "\n",
    "    ##Plot Accuracy\n",
    "    best_val_acc = max(val_accuracy)\n",
    "    best_train_acc = max(train_accuracy)\n",
    "    best_val_epoch = val_accuracy.index(best_val_acc)\n",
    "    best_train_epoch = train_accuracy.index(best_train_acc)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.gca().cla()\n",
    "    plt.ylim(0, best_train_acc+5)\n",
    "    plt.plot(train_accuracy, label='train')\n",
    "    plt.plot(val_accuracy, label='valid')\n",
    "    plt.title(\"Accuracy: best_val@{0:}-{1:.2f}, best_train@{2:}-{3:.2f}\".format(\n",
    "        float(best_val_epoch), float(best_val_acc), float(best_train_epoch), float(best_train_acc)))\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path_accu)\n",
    "\n",
    "\n",
    "    ##Plot Loss\n",
    "    best_val_loss = min(val_losses)\n",
    "    best_train_loss = min(losses)\n",
    "    best_val_epoch = val_losses.index(best_val_loss)\n",
    "    best_train_epoch = losses.index(best_train_loss)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.gca().cla()\n",
    "    plt.ylim(0, init_loss)\n",
    "    plt.plot(losses, label='train')\n",
    "    plt.plot(val_losses, label='valid')\n",
    "    plt.title(\"Loss: best_val@{0:}-{1:.2f}, best_train@{2:}-{3:.2f}\".format(\n",
    "        float(best_val_epoch), float(best_val_loss), float(best_train_epoch), float(best_train_loss)))\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Testing Data\n",
    "Loading test data similar to the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import torch\n",
    "from dataLoader import TestVideoFolder\n",
    "\n",
    "\n",
    "test_data = TestVideoFolder(root=\"./20bn-jester-v1/videos\",\n",
    "                        csv_file_input=\"./20bn-jester-v1/annotations/jester-v1-test.csv\",\n",
    "                        clip_size=18,\n",
    "                        nclips=1,\n",
    "                        step_size=2,\n",
    "                        is_val=False,\n",
    "                        )\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=10, shuffle=False,\n",
    "    num_workers=8, pin_memory=True,\n",
    "    drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "The cell also saves the results after the testing is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = classes_dct\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (input, target) in enumerate(test_loader):\n",
    "\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        # compute output and loss\n",
    "        output = model(input)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "\n",
    "        predictions.append(predicted.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Test: [{0}/{1}]\\t'.format(\n",
    "                        i, len(test_loader)))\n",
    "\n",
    "    #Add results together and make it a list\n",
    "    predictions = numpy.concatenate(predictions)\n",
    "    predictions = predictions.tolist()\n",
    "\n",
    "    #transform number gesture ids to gesture names\n",
    "    for index, row in enumerate(predictions):\n",
    "        predictions[index] = class_to_idx[row]\n",
    "    \n",
    "    #Make the predictions into a DataFrame\n",
    "    test_results = pd.DataFrame({'id_result':predictions})\n",
    "    \n",
    "    #Load the test data\n",
    "    jester_test = pd.read_csv(\"./20bn-jester-v1/annotations/jester-v1-test.csv\", header=None)\n",
    "    jester_test = pd.DataFrame(jester_test)\n",
    "    \n",
    "    #Assign the video id and gesture names to seperate columns\n",
    "    results_combined = pd.DataFrame(columns = [\"vid_id\", \"gesture_name\"])\n",
    "    results_combined[\"vid_id\"] = jester_test.iloc[:,0].astype(str)\n",
    "    results_combined[\"gesture_name\"] = \";\" + test_results.iloc[:,0]\n",
    "    \n",
    "    #write data tofile\n",
    "    results_combined.to_csv(\"./trainings/3D_CNN_models/cs523_project_model/jester-test-results.csv\", index=False, header=None, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Video Examples (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plays videos from the predicted test results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoPlay import playTrainVideo\n",
    "trainDataPath = \"./trainings/3D_CNN_models/cs523_project_model/jester-test-results.csv\"\n",
    "TestFile = True\n",
    "\n",
    "\n",
    "playTrainVideo(trainDataPath, 3, TestFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First predicts the video then displays the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoPlay import videoPrediction\n",
    "GestureId = 7 \n",
    "    \n",
    "videoPrediction(classes_dct, model, GestureId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicts the Video capture of a webcam and displays the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoPlay import play_video\n",
    "VideoCapture = 0\n",
    "\n",
    "play_video(classes_dct, model, VideoCapture)       "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f10caef94d87726fccb9d45aed145d5e0db6100c91625f6b85f3a2d543b79e5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
